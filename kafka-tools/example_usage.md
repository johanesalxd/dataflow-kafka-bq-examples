# Kafka Data Generator and Consumer Usage Examples

This document shows how to use the data generator and consumer together.

## Prerequisites

1. **Start Kafka using Docker Compose:**
   ```bash
   docker-compose up -d
   ```
   This will start Kafka (in KRaft mode) and Kafka UI containers. No ZooKeeper needed!

2. **Install required dependencies:**
   ```bash
   pip install kafka-python
   ```

3. **Access Kafka UI:** Open http://localhost:8080 in your browser to view topics and messages.

## Architecture

This setup uses **Kafka KRaft mode** (no ZooKeeper required):
- ✅ **Simpler setup** - Only Kafka and Kafka UI containers
- ✅ **Better performance** - Faster startup and lower resource usage
- ✅ **Modern architecture** - KRaft is the future of Kafka

## Connection Configuration

- **From host machine (Python scripts):** Use `localhost:9092`
- **Between containers:** Use `kafka:9092`
- **Kafka UI:** Available at http://localhost:8080

## Basic Usage

### 1. Generate Data (Producer)

Generate a batch of 50 messages for all topics:
```bash
python kafka-tools/data_generator.py --mode batch --batch-size 50
```

Generate continuous data at 30 messages per minute:
```bash
python kafka-tools/data_generator.py --mode continuous --rate 30
```

Generate data for specific topics only:
```bash
python kafka-tools/data_generator.py --topics user-events product-updates --batch-size 20
```

### 2. Consume Data (Consumer)

Consume 10 messages in batch mode:
```bash
python kafka-tools/data_consumer.py --mode batch --batch-size 10
```

Consume continuously (press Ctrl+C to stop):
```bash
python kafka-tools/data_consumer.py --mode continuous
```

Consume from the beginning of topics:
```bash
python kafka-tools/data_consumer.py --mode batch --batch-size 20 --from-beginning
```

Consume from specific topics only:
```bash
python kafka-tools/data_consumer.py --topics user-events --mode continuous
```

Use a custom consumer group:
```bash
python kafka-tools/data_consumer.py --consumer-group my-consumer-group --mode continuous
```

## Testing Together

### Terminal 1 - Start Consumer
```bash
python kafka-tools/data_consumer.py --mode continuous
```

### Terminal 2 - Generate Data
```bash
python kafka-tools/data_generator.py --mode batch --batch-size 10
```

You should see the consumer immediately display the messages generated by the producer.

## Command Line Options

### Data Generator
- `--bootstrap-servers`: Kafka servers (default: localhost:9092)
- `--mode`: batch or continuous (default: continuous)
- `--topics`: Topics to generate for (default: all three topics)
- `--batch-size`: Messages per batch (default: 100)
- `--rate`: Messages per minute per topic (default: 60)

### Data Consumer
- `--bootstrap-servers`: Kafka servers (default: localhost:9092)
- `--mode`: batch or continuous (default: continuous)
- `--topics`: Topics to consume from (default: all three topics)
- `--batch-size`: Messages to consume in batch mode (default: 10)
- `--consumer-group`: Consumer group ID (default: data-consumer-group)
- `--from-beginning`: Start from earliest messages (default: latest)

## Sample Output

The consumer will display messages in this format:
```
============================================================
Topic: user-events
Partition: 0
Offset: 42
Key: user_023
Timestamp: 2024-01-15T10:30:45.123456
Value: {
  "event_id": "evt_a1b2c3d4",
  "user_id": "user_023",
  "event_type": "purchase",
  "product_id": "prod_015",
  "timestamp": "2024-01-15T10:30:45.123456"
}
============================================================
